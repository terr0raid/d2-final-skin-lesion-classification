****# SÃ¼rÃ¼m NotlarÄ± (Release Notes)

## v0.1.0 - D2 Teslimi (Uygulama ve DerinleÅŸtirme)
**Tarih:** AralÄ±k 2025
**Kapsam:** Veri hattÄ±nÄ±n kurulmasÄ± ve Baseline (Referans) modellerin oluÅŸturulmasÄ±.

### ğŸš€ Yenilikler ve Eklenenler
* **Proje Ä°skeleti:**
    * `src/`, `notebooks/`, `data/`, `output/` dizin yapÄ±sÄ± oluÅŸturuldu.
    * `requirements.txt` ile baÄŸÄ±mlÄ±lÄ±klar sabitlendi.
* **Veri HattÄ± (Data Pipeline):**
    * HAM10000 veri seti entegrasyonu saÄŸlandÄ±.
    * **Stratified Split** ile veri dengesizliÄŸi gÃ¶zetilerek EÄŸitim (%80), DoÄŸrulama (%10) ve Test (%10) setleri ayrÄ±ldÄ±.
    * GÃ¶rÃ¼ntÃ¼ Ã¶n iÅŸleme (Resize: 224x224) ve Augmentation (sadece train set iÃ§in: Flip, Rotation) sÃ¼reÃ§leri eklendi.
* **Modeller (Baselines):**
    * **ML (Makine Ã–ÄŸrenmesi):** Random Forest ve SVM modelleri kuruldu (Girdi boyutu: 64x64 flatten).
    * **DL (Derin Ã–ÄŸrenme):** ResNet50 ve Vision Transformer (ViT-B/16) modelleri transfer Ã¶ÄŸrenme (ImageNet aÄŸÄ±rlÄ±klarÄ±) ile eÄŸitildi.
* **Raporlama:**
    * EÄŸitim/DoÄŸrulama kayÄ±p (loss) grafikleri oluÅŸturuldu.
    * Confusion Matrix ve SÄ±nÄ±flandÄ±rma RaporlarÄ± (F1-Score, Recall, Precision) `output/figures` altÄ±na eklendi.

### Reproducibility (Tekrarlanabilirlik) Bilgisi
Deneylerin tutarlÄ± ve tekrarlanabilir olmasÄ± iÃ§in tÃ¼m rastgele sÃ¼reÃ§lerde **sabit seed** kullanÄ±lmÄ±ÅŸtÄ±r.

* **Global Seed (Random State):** `42`
* **KullanÄ±ldÄ±ÄŸÄ± Yerler:**
    * Veri seti ayrÄ±mÄ± (`train_test_split` iÃ§inde `src/prepare_data.py`).
    * ML Modelleri (`RandomForestClassifier`, `SVC` baÅŸlangÄ±Ã§ parametreleri).
    * DL Modelleri (Torch/Cuda deterministic mod ayarlarÄ± - notebook iÃ§inde).

### âš ï¸ Bilinen Sorunlar / KÄ±sÄ±tlar
* SÄ±nÄ±f dengesizliÄŸi (Class Imbalance) nedeniyle ML modelleri `nv` sÄ±nÄ±fÄ±na aÅŸÄ±rÄ± uyum (overfit) gÃ¶stermektedir.
* ViT modelinin eÄŸitimi, ResNet50'ye gÃ¶re daha fazla GPU belleÄŸi ve sÃ¼re gerektirmektedir.

## ğŸ”® Gelecek SÃ¼rÃ¼m Hedefleri (v0.2.0 Roadmap)
**Odak:** Ablasyon Ã‡alÄ±ÅŸmalarÄ± (Ablation Studies) ve Model Optimizasyonu

D2 aÅŸamasÄ±nda kurulan baseline modellerin performansÄ±nÄ± artÄ±rmak ve hangi bileÅŸenin ne kadar katkÄ± saÄŸladÄ±ÄŸÄ±nÄ± Ã¶lÃ§mek iÃ§in **v0.2.0** sÃ¼rÃ¼mÃ¼nde aÅŸaÄŸÄ±daki ablasyon deneyleri planlanmÄ±ÅŸtÄ±r:

### 1. Hiperparametre AblasyonlarÄ±
Modelin Ã¶ÄŸrenme dinamiÄŸini optimize etmek iÃ§in:
* **Learning Rate Scheduler:** Sabit LR yerine `StepLR` veya `CosineAnnealing` kullanÄ±mÄ±nÄ±n yakÄ±nsama Ã¼zerindeki etkisi.
* **Weight Decay:** Overfitting (aÅŸÄ±rÄ± Ã¶ÄŸrenme) riskine karÅŸÄ± farklÄ± regÃ¼larizasyon katsayÄ±larÄ±nÄ±n (Ã¶rn. 1e-4, 1e-5) test edilmesi.
* **Batch Size:** DonanÄ±m kÄ±sÄ±tlarÄ± dahilinde gradient kararlÄ±lÄ±ÄŸÄ± Ã¼zerindeki etkinin Ã¶lÃ§Ã¼lmesi.

### 2. KayÄ±p Fonksiyonu (Loss Function) Deneyleri
SÄ±nÄ±f dengesizliÄŸini (Ã¶zellikle `nv` dominasyonunu) kÄ±rmak iÃ§in:
* **Baseline:** Standart `CrossEntropyLoss`.
* **Aday 1:** `Weighted CrossEntropy` (SÄ±nÄ±f frekansÄ±nÄ±n tersi ile aÄŸÄ±rlÄ±klandÄ±rma).
* **Aday 2:** `Focal Loss` (Modelin zorlandÄ±ÄŸÄ± Ã¶rneklere daha fazla odaklanmasÄ±).

### 3. Mimari ve Veri BileÅŸenleri
* **Augmentation Stratejisi:** Mevcut `Flip/Rotate` iÅŸlemlerine ek olarak `ColorJitter` veya `Cutout` tekniklerinin modele katkÄ±sÄ±nÄ±n izole edilmesi.
* **Backbone KarÅŸÄ±laÅŸtÄ±rmasÄ±:** ResNet50 yerine daha hafif `EfficientNet-B0` veya daha derin `ResNet101` kullanÄ±larak accuracy/hÄ±z takasÄ±nÄ±n analizi.